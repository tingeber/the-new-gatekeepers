The reliance of individuals on journalists as gatekeepers of the past is not only a quantitative process of specialization and division of labor, but also a qualitative process of assigning trust.

We, as society and social beings, tend towards specialization. Individuals create an intricate, complex web of co-dependencies between persons trained and specialized in specific tasks out of necessity. The modern societal infrastructure is inherently geared towards the impossibility of self-sufficiency in independently procuring even the basic physiological needs[^8]. The main driver of this granularization is complexity:

> A growing economy encourages individuals to avail themselves of the efficiencies of specialization and exchange, and as the division of labor becomes more elaborate, social complexity increases [(Brumfiel &amp; Earle, 1987, p. 1)](https://paperpile.com/c/BG18Wg/lzle5/?locator=1).

This specialization of labor is also reflected in the process of outsourcing responsibility for mediation and filtering of information. Procuring, filtering and categorizing information, as well as narrating it, formulating opinions, selectively presenting and setting the media agenda, is a set of tasks that has been delegated to experts. There is a distinct differentiating factor for the information domain: the expertise that has been outsourced is the formulation of opinions. It is a meta-expertise in that it filters and evaluates information about other domains. It qualifies and differentiates, sets preferences, judges and narrates. The defining difference of importance is the deeply qualitative aspect of this outsourcing: we as human beings rely on others to help us reduce the signal to noise ratio, and make considered choices.

This reliance on other specialized groups to filter content in our stead is based on trust. The trust itself has been codified over the years with frameworks, laws, codes and societal acceptance that protect, oversee, control and evaluate the process of filtering of information. In the algorithmic era, however, there are no codes of ethics or behaviour that regulate how automated filtering is implemented. We, the audience, do not currently have the ability to rely on well-defined processes of assigning trust to algorithmic content filtering. The trust mechanism towards human gatekeepers has been honed over centuries of interaction, sometimes difficult compromise, and acceptance of the humanity behind decision-making. We commonly understand, as human beings, that journalists do have their own agendas, sometimes implicitly and sometimes explicitly - as is the case with partisan media outlets that clearly state their party affiliation. The understanding and acceptance of mechanisms like bias, partisanism, and corporate affiliation, are known and relatively well understood by the modern audience. With algorithms the perception of neutrality, the lack of understanding of the implicit and explicit biases, and the inability to grasp the algorithmic process means that people have lost the cornerstone of trust relationship with gatekeepers â€” the recognition of human fallacy. This in turn might mean that we perceive algorithmic information filtering as devoid of bias, or without an agenda.

[^8]: As per the hierarchy of needs defined by Maslow _(Maslow & Lewis, 1987)_