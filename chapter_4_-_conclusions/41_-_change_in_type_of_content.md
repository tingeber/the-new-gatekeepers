While there are indications of which types of information get privileged over others (taking into consideration bias, self-amplification and other examples from chapter 3), as chapter 1 mentions, we must not forget the synecdochical nature of algorithms: they are incredibly complex systems of machine-based sorting and filtering, without a single individual being able to control or even grasp _how_ the choices are being made on a holistic level. The best we can aspire to is knowing _which_ choices are being made. In fact, the process of creation of algorithmic evaluation mechanisms is geared towards results: the algorithms are constantly fine-tuned to produce results that are in line with the algorithm owners’ agenda, and that agenda is usually solely driven by profit and return of investment, and without any legal mechanism, no matter how binding, to control or oversee the choice of results. This scenario makes it seem that we have no control whatsoever over how the information we are served is being controlled and filtered — and that assumption seems to be largely correct. Another troubling aspect of this scenario is the commonly accepted perception of neutrality of algorithms. As we have seen, there is nothing neutral about how algorithms are designed — it is rather complex, and strongly dependent on personal agendas and purchase power of groups.